{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aprendizaje Automático II - Miguel Angel Ruiz Ortiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente los siguientes clasificadores\n",
    "\n",
    "1. un Perceptrón multicapa;\n",
    "2. una Máquina de aprendizaje extremo;\n",
    "3. una Máquina de aprendizaje con pesos binarios ${-1,1}$;\n",
    "\n",
    "para clasificar datos que tienen la siguiente representación: $x_i$ una matriz de $n \\times n$ enteros (con n=12), $y_i \\in \\{0,1,2,3,4,5\\}$, donde las entradas de cada matriz se pueden interpretar como índices de columnas de otra matriz $E = d \\times m$ (d=128, m=256)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"X_train.npy\").astype(\"float32\")\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "y_train = np.load(\"y_train.npy\").astype(\"float32\")\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels without one-hot\n",
    "labels_train = np.argmax(y_train, axis=1)\n",
    "labels_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# label names\n",
    "label_2_text = {\n",
    "    0: \"anger\",\n",
    "    1: \"disgust\",\n",
    "    2: \"fear\",\n",
    "    3: \"happiness\",\n",
    "    4: \"sadness\",\n",
    "    5: \"surprise\",\n",
    "    6: \"neutral\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones útiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que evalua el modelo dado (model) en los datos de entrenamiento (X_train) y datos de prueba dados (X_test). Imprime la precisión, recall y matriz de confusión en cada dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_info(model, X_train, X_test):\n",
    "    # predictions - argmax to retrieve label with highest probability\n",
    "    y_pred_train = tf.argmax(model.predict(X_train), axis=1)\n",
    "    y_pred_test = tf.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "    print(\"Precisión en datos de entrenamiento:\", accuracy_score(labels_train, y_pred_train))\n",
    "    print(\"Precisión en datos de prueba:\", accuracy_score(labels_test, y_pred_test))\n",
    "    print(\"Recall en datos de entrenamiento:\", recall_score(labels_train, y_pred_train, average=\"macro\"))\n",
    "    print(\"Recall en datos de prueba:\", recall_score(labels_test, y_pred_test, average=\"macro\"))\n",
    "    print(\"\\nMatriz de confusión en datos de entrenamiento:\")\n",
    "    print(confusion_matrix(labels_train, y_pred_train))\n",
    "    print(\"\\nMatriz de confusión en datos de prueba:\")\n",
    "    print(confusion_matrix(labels_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Precisión en datos de entrenamiento: 0.9665126050420169\n",
      "Precisión en datos de prueba: 0.24933333333333332\n",
      "Recall en datos de entrenamiento: 0.9640258777385846\n",
      "Recall en datos de prueba: 0.23453810440888753\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[3182    0   11   38   35    5   32]\n",
      " [   2  359    1    5    5    3    2]\n",
      " [  39    2 3218   71   44   25   10]\n",
      " [  35    0   11 5824   42    8   27]\n",
      " [  12    0   11   52 3904   14   18]\n",
      " [  11    0    5   11   10 2605   10]\n",
      " [  26    1   14   65   75    9 3911]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[122   3  63 231 121  45 106]\n",
      " [  7  16   3  19  13   6  15]\n",
      " [ 89   1 135 240 128  75  85]\n",
      " [162   5 116 482 241 106 191]\n",
      " [113   1  79 322 223  67 132]\n",
      " [ 59   3  30 158  79 172  68]\n",
      " [115   0  73 317 177  77 159]]\n"
     ]
    }
   ],
   "source": [
    "mlp_model_path = \"mlp_model.keras\"\n",
    "mlp_model = keras.models.load_model(mlp_model_path)\n",
    "print_model_info(mlp_model, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación Extreme Learning Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos que cargamos de EML no tienen la capa *softmax* al final, pero dado que estamos tomando *argmax* al final para predecir la etiqueta no influye en la predicción. Es decir, $\\argmax(\\vec{x}) = \\argmax(softmax(\\vec{x}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step\n",
      "Precisión en datos de entrenamiento: 0.39046218487394957\n",
      "Precisión en datos de prueba: 0.20742857142857143\n",
      "Recall en datos de entrenamiento: 0.3181230994918591\n",
      "Recall en datos de prueba: 0.159195563370842\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[ 839    0  319 1168  435  145  397]\n",
      " [  28   15   40  138   64   22   70]\n",
      " [ 218    0 1015 1145  454  155  422]\n",
      " [ 330    0  383 3781  614  228  611]\n",
      " [ 271    0  282 1332 1480  157  489]\n",
      " [ 157    0  197  893  324  774  307]\n",
      " [ 293    0  293 1424  507  195 1389]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[ 72   0  81 286 101  39 112]\n",
      " [  5   2   8  33  14   3  14]\n",
      " [ 66   0  89 304 138  62  94]\n",
      " [114   0 117 548 212  83 229]\n",
      " [ 85   0 101 405 170  38 138]\n",
      " [ 56   0  47 245  95  57  69]\n",
      " [ 85   0 105 381 144  52 151]]\n"
     ]
    }
   ],
   "source": [
    "eml_simple_path = \"eml_simple.keras\"\n",
    "eml_simple = keras.models.load_model(eml_simple_path)\n",
    "print_model_info(eml_simple, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step\n",
      "Precisión en datos de entrenamiento: 0.39046218487394957\n",
      "Precisión en datos de prueba: 0.20742857142857143\n",
      "Recall en datos de entrenamiento: 0.3181230994918591\n",
      "Recall en datos de prueba: 0.159195563370842\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[ 839    0  319 1168  435  145  397]\n",
      " [  28   15   40  138   64   22   70]\n",
      " [ 218    0 1015 1145  454  155  422]\n",
      " [ 330    0  383 3781  614  228  611]\n",
      " [ 271    0  282 1332 1480  157  489]\n",
      " [ 157    0  197  893  324  774  307]\n",
      " [ 293    0  293 1424  507  195 1389]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[ 72   0  81 286 101  39 112]\n",
      " [  5   2   8  33  14   3  14]\n",
      " [ 66   0  89 304 138  62  94]\n",
      " [114   0 117 548 212  83 229]\n",
      " [ 85   0 101 405 170  38 138]\n",
      " [ 56   0  47 245  95  57  69]\n",
      " [ 85   0 105 381 144  52 151]]\n"
     ]
    }
   ],
   "source": [
    "eml_ridge_path = \"eml_ridge.keras\"\n",
    "eml_ridge = keras.models.load_model(eml_ridge_path)\n",
    "print_model_info(eml_ridge, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n",
      "Precisión en datos de entrenamiento: 0.24987394957983194\n",
      "Precisión en datos de prueba: 0.24819047619047618\n",
      "Recall en datos de entrenamiento: 0.14285714285714285\n",
      "Recall en datos de prueba: 0.14285714285714285\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[   0    0    0 3303    0    0    0]\n",
      " [   0    0    0  377    0    0    0]\n",
      " [   0    0    0 3409    0    0    0]\n",
      " [   0    0    0 5947    0    0    0]\n",
      " [   0    0    0 4011    0    0    0]\n",
      " [   0    0    0 2652    0    0    0]\n",
      " [   0    0    0 4101    0    0    0]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[   0    0    0  691    0    0    0]\n",
      " [   0    0    0   79    0    0    0]\n",
      " [   0    0    0  753    0    0    0]\n",
      " [   0    0    0 1303    0    0    0]\n",
      " [   0    0    0  937    0    0    0]\n",
      " [   0    0    0  569    0    0    0]\n",
      " [   0    0    0  918    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "eml_lasso_path = \"eml_lasso.keras\"\n",
    "eml_lasso = keras.models.load_model(eml_lasso_path)\n",
    "print_model_info(eml_lasso, X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización Elastic-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step\n",
      "Precisión en datos de entrenamiento: 0.24987394957983194\n",
      "Precisión en datos de prueba: 0.24819047619047618\n",
      "Recall en datos de entrenamiento: 0.14285714285714285\n",
      "Recall en datos de prueba: 0.14285714285714285\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[   0    0    0 3303    0    0    0]\n",
      " [   0    0    0  377    0    0    0]\n",
      " [   0    0    0 3409    0    0    0]\n",
      " [   0    0    0 5947    0    0    0]\n",
      " [   0    0    0 4011    0    0    0]\n",
      " [   0    0    0 2652    0    0    0]\n",
      " [   0    0    0 4101    0    0    0]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[   0    0    0  691    0    0    0]\n",
      " [   0    0    0   79    0    0    0]\n",
      " [   0    0    0  753    0    0    0]\n",
      " [   0    0    0 1303    0    0    0]\n",
      " [   0    0    0  937    0    0    0]\n",
      " [   0    0    0  569    0    0    0]\n",
      " [   0    0    0  918    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "eml_elasticnet_path = \"eml_elasticnet.keras\"\n",
    "eml_elasticnet = keras.models.load_model(eml_elasticnet_path)\n",
    "print_model_info(eml_elasticnet, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos binarios, sin regularización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step\n",
      "Precisión en datos de entrenamiento: 0.3923109243697479\n",
      "Precisión en datos de prueba: 0.2144761904761905\n",
      "Recall en datos de entrenamiento: 0.3179137343211312\n",
      "Recall en datos de prueba: 0.16234230880328274\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[ 933    0  238 1109  406  178  439]\n",
      " [  40    7   45  155   45   18   67]\n",
      " [ 265    0  979 1151  403  181  430]\n",
      " [ 366    0  399 3759  584  220  619]\n",
      " [ 302    0  273 1339 1417  197  483]\n",
      " [ 163    0  236  837  311  789  316]\n",
      " [ 286    0  320 1339  508  195 1453]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[ 75   0  63 276 105  59 113]\n",
      " [ 10   0  10  29   9   5  16]\n",
      " [ 76   0  88 292 100  65 132]\n",
      " [127   0 136 562 170  98 210]\n",
      " [ 99   0  79 381 177  54 147]\n",
      " [ 62   0  66 214  74  70  83]\n",
      " [103   0  86 390 127  58 154]]\n"
     ]
    }
   ],
   "source": [
    "eml_bin_simple_path = \"eml_bin_simple.keras\"\n",
    "eml_bin_simple = keras.models.load_model(eml_bin_simple_path)\n",
    "print_model_info(eml_bin_simple, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos binarios, regularización Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step\n",
      "Precisión en datos de entrenamiento: 0.39474789915966385\n",
      "Precisión en datos de prueba: 0.21257142857142858\n",
      "Recall en datos de entrenamiento: 0.32105438202834496\n",
      "Recall en datos de prueba: 0.16468803220720618\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[ 843    0  261 1155  442  157  445]\n",
      " [  27   13   40  142   56   29   70]\n",
      " [ 219    0 1023 1178  424  145  420]\n",
      " [ 370    0  401 3755  565  198  658]\n",
      " [ 261    0  298 1255 1455  191  551]\n",
      " [ 156    0  249  834  323  759  331]\n",
      " [ 250    0  307 1324  492  181 1547]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[ 62   0  88 265  85  56 135]\n",
      " [ 12   2   6  35  10   2  12]\n",
      " [ 60   0 107 288 136  49 113]\n",
      " [110   0 130 547 197  84 235]\n",
      " [ 84   0 105 363 171  67 147]\n",
      " [ 46   0  63 218  75  69  98]\n",
      " [ 76   0 103 366 142  73 158]]\n"
     ]
    }
   ],
   "source": [
    "eml_bin_ridge_path = \"eml_bin_ridge.keras\"\n",
    "eml_bin_ridge = keras.models.load_model(eml_bin_ridge_path)\n",
    "print_model_info(eml_bin_ridge, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos binarios, regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step\n",
      "Precisión en datos de entrenamiento: 0.24987394957983194\n",
      "Precisión en datos de prueba: 0.24819047619047618\n",
      "Recall en datos de entrenamiento: 0.14285714285714285\n",
      "Recall en datos de prueba: 0.14285714285714285\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[   0    0    0 3303    0    0    0]\n",
      " [   0    0    0  377    0    0    0]\n",
      " [   0    0    0 3409    0    0    0]\n",
      " [   0    0    0 5947    0    0    0]\n",
      " [   0    0    0 4011    0    0    0]\n",
      " [   0    0    0 2652    0    0    0]\n",
      " [   0    0    0 4101    0    0    0]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[   0    0    0  691    0    0    0]\n",
      " [   0    0    0   79    0    0    0]\n",
      " [   0    0    0  753    0    0    0]\n",
      " [   0    0    0 1303    0    0    0]\n",
      " [   0    0    0  937    0    0    0]\n",
      " [   0    0    0  569    0    0    0]\n",
      " [   0    0    0  918    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "eml_bin_lasso_path = \"eml_bin_lasso.keras\"\n",
    "eml_bin_lasso = keras.models.load_model(eml_bin_lasso_path)\n",
    "print_model_info(eml_bin_lasso, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos binarios, regularización Elastic-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step\n",
      "Precisión en datos de entrenamiento: 0.25\n",
      "Precisión en datos de prueba: 0.24819047619047618\n",
      "Recall en datos de entrenamiento: 0.14313856304119463\n",
      "Recall en datos de prueba: 0.14294594872301866\n",
      "\n",
      "Matriz de confusión en datos de entrenamiento:\n",
      "[[   0    0    0 3287    6    0   10]\n",
      " [   0    0    0  376    0    0    1]\n",
      " [   0    0    0 3394    0    0   15]\n",
      " [   0    0    0 5931    3    0   13]\n",
      " [   0    0    0 3995    5    0   11]\n",
      " [   0    0    0 2641    3    0    8]\n",
      " [   0    0    0 4082    5    0   14]]\n",
      "\n",
      "Matriz de confusión en datos de prueba:\n",
      "[[   0    0    0  689    1    0    1]\n",
      " [   0    0    0   79    0    0    0]\n",
      " [   0    0    0  750    1    0    2]\n",
      " [   0    0    0 1301    0    0    2]\n",
      " [   0    0    0  930    1    0    6]\n",
      " [   0    0    0  565    3    0    1]\n",
      " [   0    0    0  916    1    0    1]]\n"
     ]
    }
   ],
   "source": [
    "eml_bin_elasticnet_path = \"eml_bin_elasticnet.keras\"\n",
    "eml_bin_elasticnet = keras.models.load_model(eml_bin_elasticnet_path)\n",
    "print_model_info(eml_bin_elasticnet, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero observamos que al trabajar con las matrices con entradas enteras, los modelos tenían problemas para obtener buena precisión **incluso** en el conjunto de entrenamiento. Es curioso que cuando normalizamos (estandarizamos) los datos, el perceptrón multicapa encontraba más fácil clasificar los datos de entrenamiento, llegando al 96%, pero aún así en el conjunto de validación/prueba no tenía buen rendimiento. \n",
    "\n",
    "El bajo rendimiento se encontró en todos los modelos, teniendo un máximo de una precisión del 25% en el conjunto de prueba. Aunque hay que tener cuidado porque hay modelos como el EML con regularización Lasso y Elastic-Net (con pesos binarios y no binarios) que predecían casi siempre la etiqueta *felicidad* (3), la cual es la etiqueta dominante, y con eso ya alcanzaban el 25%. Sin embargo, dichos modelos eran penalizados a través de la métrica *recall* y eran los más bajos en esta métrica. Recordemos que el *recall* es un promedio de la proporción de verdaderos positivos en cada clase. De manera que las clases que no eran felicidad tenían una proporción casi 0 de verdaderos positivos con esos modelos. Es razonable pensar que la regularización Lasso y Elastic-Net no favorece a las EML porque la matriz $\\beta$ debe capturar toda la información del modelo y esas regularizaciones hacen que $\\beta$ sea esparsa, i.e, menos capacidad de información que puede guardar $\\beta$.\n",
    "\n",
    "A continuación se muestra un resumen en la siguiente tabla con el rendimiento de los modelos en el conjunto de prueba.\n",
    "\n",
    "| Modelo                           | Precisión | Recall |\n",
    "|----------------------------------|-----------|--------|\n",
    "| Perceptrón Multicapa             | 0.249     | 0.234  |\n",
    "| EML                              | 0.207     | 0.159  |\n",
    "| EML + Ridge                      | 0.207     | 0.159  |\n",
    "| EML + Lasso                      | 0.248     | 0.142  |\n",
    "| EML + Elastic-Net                | 0.248     | 0.142  |\n",
    "| EML + p. binarios                | 0.214     | 0.162  |\n",
    "| EML + p. binarios + Ridge        | 0.212     | 0.164  |\n",
    "| EML + p. binarios + Lasso        | 0.248     | 0.142  |\n",
    "| EML + p. binarios + Elastic-Net  | 0.248     | 0.142  |\n",
    "\n",
    "Observemos que el mejor modelo fue el perceptrón multicapa, con un *recall* con casi 10 puntos porcentuales más grande comparado con los demás modelos. Otro comportamiento que cabe resaltar es que los EML con pesos binarios sin regularización y con regularización Ridge son ligeramente mejores que con pesos no binarios (en precisión y en *recall*).\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
